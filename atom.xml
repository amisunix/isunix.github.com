<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Steven's Blog]]></title>
  <link href="http://isunix.github.io/atom.xml" rel="self"/>
  <link href="http://isunix.github.io/"/>
  <updated>2019-07-07T07:36:23+08:00</updated>
  <id>http://isunix.github.io/</id>
  <author>
    <name><![CDATA[Steven Sun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[机器学习的流程图]]></title>
    <link href="http://isunix.github.io/blog/2019/07/07/ji-qi-xue-xi-de-liu-cheng-tu/"/>
    <updated>2019-07-07T07:32:15+08:00</updated>
    <id>http://isunix.github.io/blog/2019/07/07/ji-qi-xue-xi-de-liu-cheng-tu</id>
    <content type="html"><![CDATA[<p>下面的机器学习的一个流程图是从某视频中看到的，现在记录如下:</p>

<p><img src="http://isunix.github.io/images/sun/machine_learning_flow.001.jpeg" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[R语言的一些记录]]></title>
    <link href="http://isunix.github.io/blog/2019/07/05/ryu-yan-de-%5B%3F%5D-xie-ji-lu/"/>
    <updated>2019-07-05T08:00:01+08:00</updated>
    <id>http://isunix.github.io/blog/2019/07/05/ryu-yan-de-[?]-xie-ji-lu</id>
    <content type="html"><![CDATA[<p>在R语言中，如果我们有一个<code>vector</code> 叫 <code>x</code>, <code>x</code> 的值中有 <code>NA</code>，如果我们想要过滤掉 <code>x</code> 中的 <code>NA</code>, 并把过滤后的结果，赋值给变量 <code>y</code>， 可以如下操作:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">y <span class="o">&lt;-</span> x<span class="p">[</span><span class="o">!</span>is.na<span class="p">(</span>x<span class="p">)]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果我们再想找出 <code>y</code> 中元素大于0的元素，可以如下操作L:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">y<span class="p">[</span>y <span class="o">&gt;</span> <span class="m">0</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>以上两步合在一起，可以如下操作:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">x<span class="p">[</span><span class="o">!</span>is.na<span class="p">(</span>x<span class="p">)</span> <span class="o">&amp;</span> x <span class="o">&gt;</span> <span class="m">0</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果我们直接使用 <code>x[x &gt; 0]</code> 是不行的，会得到如下的包含<code>NA</code> 值的一个 <code>vector</code>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="r"><span class="line"> <span class="kc">NA</span>        <span class="kc">NA</span> <span class="m">0.3488261</span>        <span class="kc">NA</span> <span class="m">2.4099262</span>        <span class="kc">NA</span>        <span class="kc">NA</span>        <span class="kc">NA</span>        <span class="kc">NA</span>        <span class="kc">NA</span> <span class="m">0.4626879</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据分析和机器学习一些摘抄]]></title>
    <link href="http://isunix.github.io/blog/2019/07/04/shu-ju-fen-xi-he-ji-qi-xue-xi-%5B%3F%5D-xie-zhai-chao/"/>
    <updated>2019-07-04T18:24:50+08:00</updated>
    <id>http://isunix.github.io/blog/2019/07/04/shu-ju-fen-xi-he-ji-qi-xue-xi-[?]-xie-zhai-chao</id>
    <content type="html"><![CDATA[<ul>
  <li>怎么对待缺失值</li>
</ul>

<p><code>Missing values play an important role in statistics and data analysis. Often, missing values must not be ignored, but rather they should be carefully
| studied to see if there's an underlying pattern or cause for their missingness.</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[最近的工作的一些感想]]></title>
    <link href="http://isunix.github.io/blog/2019/07/04/zui-jin-de-gong-zuo-de-%5B%3F%5D-xie-gan-xiang/"/>
    <updated>2019-07-04T12:04:30+08:00</updated>
    <id>http://isunix.github.io/blog/2019/07/04/zui-jin-de-gong-zuo-de-[?]-xie-gan-xiang</id>
    <content type="html"><![CDATA[<h3 id="section">2019年年中开始，后面的工作内容应该有所调整。</h3>

<p>自从16年6月底，从上海回到合肥，加入到华米科技， 到现在整整3年了。 </p>

<p>从16年年中，到17年年初，基本一个人在做数据分析和报表。17年初到18年中， 带了一个新加入的同事A一起做数据分析和ETL等相关工作。 18年中，A去做上游的导数的事情，分析由我和新加入的B和C, 两个妹子，一起来完成，同时，自己也从大数据工程师，升级成了高级大数据工程师。 </p>

<p>到了19年年中，撇去一些不开心的因素(导火索吧), 为什么想从大数据分析，转到算法团队(人工智能实验室团队)去做点事情呢？ 我想主要还是想去了解数据探索的一个实用的套路吧。毕竟，描述性的统计分析，这个我已经做了三年了。 而关于数据的更地道的挖掘和分析，特征选取，建模， 模型评估这些，都是自己的薄弱点。也是我所认为的一个合格的<code>data scientist</code>必须掌握的。更何况，自己在算法和机器学习这块，并非是没有基础。人生那么长，总不能一辈子做基础的描述性的统计分析/业务分析还有做报表吧。</p>

<p>下面列出一些以前学习过的课程和材料吧, 算是对过往准备工作的一个总结。 </p>

<ul>
  <li>
    <p><code>台大林轩田的&lt;机器学习基石&gt;， &lt;机器学习技巧&gt; 和 对应的英文教材 &lt;Learning From Data&gt;</code></p>
  </li>
  <li>
    <p><code>吴恩达的&lt;机器学习&gt; 和 &lt;深度学习&gt;课程， 并且完成了coursera上的深度学习的几门课程(课后作业有点水，因为很多都可以通过上下文得到， 但是不得不承认，是好的课后作业)</code></p>
  </li>
  <li>
    <p><code>北京交通大学的桑基韬等人在网易云课堂上开的&lt;深度学习&gt;课程</code></p>
  </li>
  <li>
    <p><code>周志华的西瓜书&lt;机器学习&gt;</code></p>
  </li>
  <li>
    <p><code>李航的&lt;统计学习方法&gt;</code></p>
  </li>
  <li>
    <p><code>&lt;The Elements of Statistical Learning&gt; 看了一点点</code></p>
  </li>
  <li>
    <p><code>概率统计和线性代数的相关知识平时都有所复习</code></p>
  </li>
  <li>
    <p><code>scikit-learn, pandas 的了解和使用</code></p>
  </li>
  <li>
    <p><code>用逻辑回归和时间序列分析，做过点探索分析; 时间序列分析结果，还在团队内部进行过分享</code></p>
  </li>
  <li>
    <p><code>用深度学习的cnn方法，做过一个图片的分类程序(判断照片好看是不那么好看)</code></p>
  </li>
  <li>
    <p><code>使用过算法包跑算法，并且验证算法检测结果，计算FN, FP, TN, TP</code>.</p>
  </li>
  <li>
    <p><code>在来华米科技之前, 做了三年多的防垃圾邮件工作， 文本处理相关的原理和技术，非常熟悉了</code></p>
  </li>
</ul>

<p>准备不少，现在缺乏啥呢？ </p>

<ul>
  <li>
    <p><code>缺少对机器学习和深度学习算法的深刻理解，手写算法的能力</code></p>
  </li>
  <li>
    <p><code>缺少数据挖掘和更深层次的统计分析的流程认知</code></p>
  </li>
  <li>
    <p><code>缺乏项目经验</code></p>
  </li>
</ul>

<h2 id="section-1">希望一切都好，毕竟我才30岁。</h2>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Numpy的一些数据处理备忘]]></title>
    <link href="http://isunix.github.io/blog/2019/07/04/numpyde-%5B%3F%5D-xie-shu-ju-chu-li-bei-wang/"/>
    <updated>2019-07-04T11:43:34+08:00</updated>
    <id>http://isunix.github.io/blog/2019/07/04/numpyde-[?]-xie-shu-ju-chu-li-bei-wang</id>
    <content type="html"><![CDATA[<h2 id="numpy">记录numpy中的一些数据处理的方法.</h2>

<p>比如我们通过如下的方式，获取到了iris的数据,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span><span class="line">
</span><span class="line"><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span><span class="line"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s">&#39;petal length&#39;</span><span class="p">,</span> <span class="s">&#39;petal width&#39;</span><span class="p">,</span> <span class="s">&#39;label&#39;</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果我们想要去取第一列，第二列，和最后一列(label), 可以使用如下的方式:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">100</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>df.shape</code> 是 <code>(150, 5)</code>, <code>data.shape</code> 是 <code>(100, 3)</code></p>

<p><code>data</code> 现在是<code>lists in list</code> 的一个<code>ndarray</code></p>

<p>如果我们想要去取<code>data</code>的每行的前两列， 还有最后一列，可以使用如下的方式:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>X, y</code> 都是 ndarray. <code>x.shape</code> 是 <code>(100, 2)</code>, <code>y.shape</code> 是 <code>(100,)</code></p>

<p>如果要对标签进行二分类，我们可以使用 python 的 list comprehension:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>这样处理了之后，y 的 shape 还是跟之前是一样的.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[用Python来发送markdown格式的邮件]]></title>
    <link href="http://isunix.github.io/blog/2019/07/02/yong-pythonlai-fa-song-markdownge-shi-de-you-jian/"/>
    <updated>2019-07-02T15:19:06+08:00</updated>
    <id>http://isunix.github.io/blog/2019/07/02/yong-pythonlai-fa-song-markdownge-shi-de-you-jian</id>
    <content type="html"><![CDATA[<h2 id="httpsgithubcomyejianyemdmail">https://github.com/yejianye/mdmail</h2>

<p>mdmail， 这个是一个支持用 markdown 格式来发送邮件的工具.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="py"><span class="line"><span class="kn">import</span> <span class="nn">mdmail</span>
</span><span class="line">
</span><span class="line"><span class="n">email</span><span class="o">=</span><span class="s">&quot;&quot;&quot;</span>
</span><span class="line"><span class="s"># Sample Email</span>
</span><span class="line"><span class="s">- Python is awesome</span>
</span><span class="line"><span class="s">- Markdown is cool</span>
</span><span class="line"><span class="s">&quot;&quot;&quot;</span>
</span><span class="line">
</span><span class="line"><span class="n">mdmail</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">email</span><span class="p">,</span> <span class="n">subject</span><span class="o">=</span><span class="s">&#39;Sample Email Mdmail&#39;</span><span class="p">,</span>
</span><span class="line">            <span class="n">from_email</span><span class="o">=</span><span class="s">&#39;mypeacelover@163.com&#39;</span><span class="p">,</span> <span class="n">to_email</span><span class="o">=</span><span class="s">&#39;mypeacelover@163.com&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>很好用, 汪汪.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zeppelin搭配Presto]]></title>
    <link href="http://isunix.github.io/blog/2019/06/10/zeppelinda-pei-presto/"/>
    <updated>2019-06-10T17:57:13+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/10/zeppelinda-pei-presto</id>
    <content type="html"><![CDATA[<p>参考文章</p>

<p><code>https://stackoverflow.com/questions/35858606/presto-interpreter-in-zeppelin-on-emr</code></p>

<ul>
  <li>在 master 机器上安装 jdbc</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sudo /usr/lib/zeppelin/bin/install-interpreter.sh --name jdbc
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sudo stop zeppelin
</span><span class="line">sudo start zeppelin
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EMR中创建HUE的superuser]]></title>
    <link href="http://isunix.github.io/blog/2019/06/10/emrzhong-chuang-jian-huede-superuser/"/>
    <updated>2019-06-10T17:48:43+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/10/emrzhong-chuang-jian-huede-superuser</id>
    <content type="html"><![CDATA[<p>想要在 EMR 中创建 HUE 的 superuser， 可以使用如下的方式</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nb">cd</span> /usr/lib/hue/
</span><span class="line">sudo build/env/bin/hue  createsuperuser
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CentOS中安装nodejs]]></title>
    <link href="http://isunix.github.io/blog/2019/06/06/centoszhong-an-zhuang-nodejs/"/>
    <updated>2019-06-06T14:52:04+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/06/centoszhong-an-zhuang-nodejs</id>
    <content type="html"><![CDATA[<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">curl --silent --location https://rpm.nodesource.com/setup_8.x | sudo bash -
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sudo yum -y install nodejs
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CentOS中修改时区]]></title>
    <link href="http://isunix.github.io/blog/2019/06/06/centoszhong-xiu-gai-shi-qu/"/>
    <updated>2019-06-06T14:33:59+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/06/centoszhong-xiu-gai-shi-qu</id>
    <content type="html"><![CDATA[<p>使用如下的命令来列出时区: <code>shtimedatectl list-timezones</code></p>

<p>修改时区：<code>timedatectl set-timezone Asia/Shanghai</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AmazonEC2中修改时区]]></title>
    <link href="http://isunix.github.io/blog/2019/06/06/amazonec2zhong-xiu-gai-shi-qu/"/>
    <updated>2019-06-06T14:33:07+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/06/amazonec2zhong-xiu-gai-shi-qu</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Presto问题debug]]></title>
    <link href="http://isunix.github.io/blog/2019/06/04/prestowen-ti-debug/"/>
    <updated>2019-06-04T10:27:51+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/04/prestowen-ti-debug</id>
    <content type="html"><![CDATA[<p>我们在执行presto-cli命名的时候，可以使用如下的方式 <code>presto-cli --catalog hive --schema $schema --output-format CSV_HEADER --server $ip:$port --debug</code></p>

<p>这样就会打印出诊断信息出来.</p>

<p>我们使用如下的命令看下presto-server的状态 <code>initctl list | grep -i presto</code></p>

<p><code>sudo stop presto-server</code> 这样来关闭 presto-server； <code>sudo start presto-server</code> 这样来开启.</p>

<p>如果想要看查看presto的log，可以去 <code>/var/log/presto</code>, 对于debug非常有用.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PySpark中引入col函数的方式]]></title>
    <link href="http://isunix.github.io/blog/2019/06/04/pysparkzhong-yin-ru-colhan-shu-de-fang-shi/"/>
    <updated>2019-06-04T08:59:32+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/04/pysparkzhong-yin-ru-colhan-shu-de-fang-shi</id>
    <content type="html"><![CDATA[<p>在python代码中通过 <code>from pyspark.sql.functions import col</code> 来引入 <code>col</code> 这个函数的时候，总是报错，找不到这个函数. 后来参考
<a href="https://stackoverflow.com/questions/40163106/cannot-find-col-function-in-pyspark">https://stackoverflow.com/questions/40163106/cannot-find-col-function-in-pyspark</a> 这个文章, <code>pip install pyspark-stubs</code> 再去引用就好了.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Git上传大文件]]></title>
    <link href="http://isunix.github.io/blog/2019/06/03/gitshang-chuan-da-wen-jian/"/>
    <updated>2019-06-03T09:28:32+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/03/gitshang-chuan-da-wen-jian</id>
    <content type="html"><![CDATA[<p>我们如果需要上传大文件到git，比如数据集，可以使用Git Large File Storage <a href="https://git-lfs.github.com">https://git-lfs.github.com</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pipenv使用备忘]]></title>
    <link href="http://isunix.github.io/blog/2019/05/31/pipenvshi-yong-bei-wang/"/>
    <updated>2019-05-31T08:22:14+08:00</updated>
    <id>http://isunix.github.io/blog/2019/05/31/pipenvshi-yong-bei-wang</id>
    <content type="html"><![CDATA[<p>我在某个python环境下有很多包，我们使用如下的命令把这些包给输出到requirements.txt里去</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">pip freeze &gt; requirements.txt
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后我们使用pipenv来创建一个虚拟环境</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">mkdir xxx <span class="o">&amp;&amp;</span> mv requirements.txt xxx <span class="o">&amp;&amp;</span> <span class="nb">cd </span>xxx
</span><span class="line">pipenv --python 3.6
</span><span class="line">pipenv shell
</span><span class="line">pipenv install --dev
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>如果我们想删除创建的virtualenv, 可以</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">pipenv --rm
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>也可以到<code>~/.local/share/virtualenvs</code>下面去手动删除.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用豆瓣源安装python包]]></title>
    <link href="http://isunix.github.io/blog/2019/05/31/shi-yong-dou-ban-yuan-an-zhuang-pythonbao/"/>
    <updated>2019-05-31T08:01:15+08:00</updated>
    <id>http://isunix.github.io/blog/2019/05/31/shi-yong-dou-ban-yuan-an-zhuang-pythonbao</id>
    <content type="html"><![CDATA[<p>我们在使用pip安装python的包的时候，可以使用豆瓣源来提高下载速度</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">pip  install  requests -i  https://pypi.doubanio.com/simple/  --trusted-host pypi.doubanio.com
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>在linux和mac上，我们可以在$HOME/.pip/pip.conf里面，写入如下的内容, 那样就不用每次都像上面那样写那么长的一大串了</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="o">[</span>global<span class="o">]</span>
</span><span class="line">index-url <span class="o">=</span> https://pypi.doubanio.com/simple
</span><span class="line"><span class="o">[</span>install<span class="o">]</span>
</span><span class="line">trusted-host <span class="o">=</span> pypi.doubanio.com
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop权威指南ncdc数据准备工作备忘]]></title>
    <link href="http://isunix.github.io/blog/2019/05/30/hadoopquan-wei-zhi-nan-ncdcshu-ju-zhun-bei-gong-zuo-bei-wang/"/>
    <updated>2019-05-30T09:23:39+08:00</updated>
    <id>http://isunix.github.io/blog/2019/05/30/hadoopquan-wei-zhi-nan-ncdcshu-ju-zhun-bei-gong-zuo-bei-wang</id>
    <content type="html"><![CDATA[<p>&lt;Hadoop: The Definitive Guide, Fourth Edition&gt; <a href="http://hadoopbook.com">http://hadoopbook.com</a> 是本好书, 书中的例子用到了ncdc的数据<a href="ftp://ftp.ncdc.noaa.gov/pub/data/gsod/">ftp://ftp.ncdc.noaa.gov/pub/data/gsod/</a>，这个也是非常赞的。我们知道统计学大师Fisher当年就是在气象工作站，研究气象数据很多年，后来在统计学上面做出了卓越的成就。气象数据纷繁复杂，通过实际的气象数据来阅读这本书，会教会读者在真实的情况下，如何面对数据，这个要比用一些dummy数据做演示，效果好太多.</p>

<p>官网github上面的数据很少<a href="https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all">https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all</a>. 我们自己从上面的ncdc的链接中去下载，我们下载tar文件. 具体也可以参考这篇文章<a href="https://blog.csdn.net/mrcharles/article/details/50442367">https://blog.csdn.net/mrcharles/article/details/50442367</a></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="c">#这里cd到你想下载到的目录, 每个文件的格式如下所示gsod_1901.tar, 发现tar文件竟然只有从1930年才不是空文件</span>
</span><span class="line"><span class="nv">cdir</span><span class="o">=</span><span class="s2">&quot;$(cd `dirname $0`; pwd)&quot;</span>
</span><span class="line">
</span><span class="line"><span class="k">for </span>i in <span class="k">$(</span>seq 1930 1960<span class="k">)</span>
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">    </span>wget --execute <span class="nv">robots</span><span class="o">=</span>off —accept<span class="o">=</span>tar -r -np -nH --cut-dirs<span class="o">=</span>4 - R index.html* ftp://ftp.ncdc.noaa.gov/pub/data/gsod/<span class="nv">$i</span>/
</span><span class="line"><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>下载好了之后，我们把这些1930/gsod_1930.tar 之类的文件，重新命令为1930/1930.tar, 然后把所有的文件都放到一个本地的目录，起名叫gsod， 现在gsod目录里都是1930/1930.tar这样的文件了.</p>

<p>接下来我们在hdfs上创建目录，</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -mkdir /GSOD /GSOD_ALL
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后将本地的gsod文件夹里的文件都上传到/GSOD/里面去</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -put gsod/* /GSOD/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>这个过程在我的本机上，先是出现了namenode找不到的问题，然后又出现了namenode in safemode，创建不了的问题, 解决办法是</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">stop-all.sh
</span><span class="line">hdfs namenode -format
</span><span class="line">start-all.sh
</span><span class="line">hadoop dfsadmin -safemode leave
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后重新执行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -put gsod/* /GSOD/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>接下来我们要做的就是在hadoop上处理这些数据了. 首先创建generate_input_list.sh来生成MR的input文件:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="nv">a</span><span class="o">=</span><span class="nv">$1</span>
</span><span class="line">rm -rf ncdc_files.txt
</span><span class="line">hdfs dfs -rm /ncdc_files.txt
</span><span class="line">
</span><span class="line"><span class="k">while</span> <span class="o">[</span> <span class="nv">$a</span> -le <span class="nv">$2</span> <span class="o">]</span>
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">        </span><span class="nv">filename</span><span class="o">=</span><span class="s2">&quot;/GSOD/${a}/${a}.tar&quot;</span>
</span><span class="line">        <span class="nb">echo</span> <span class="s2">&quot;$filename&quot;</span> &gt;&gt; ncdc_files.txt
</span><span class="line">        <span class="nv">a</span><span class="o">=</span><span class="sb">`</span>expr <span class="nv">$a</span> + 1<span class="sb">`</span>
</span><span class="line"><span class="k">done</span>
</span><span class="line">
</span><span class="line">hdfs dfs -put ncdc_files.txt /
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>ncdc_files.txt中的每一行就是<code>/GSOD/1950/1950.tar</code>这样的数据.</p>

<p>然后我们来产生文件:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sh generate_input_list.sh 1901 1956
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>接下来我们来创建load_ncdc_map.sh脚本，在MapReduce的Streaming上正常运行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="nb">read </span>offset hdfs_file
</span><span class="line"><span class="nb">echo</span> -e <span class="s2">&quot;$offset\t$hdfs_file&quot;</span>
</span><span class="line">
</span><span class="line"><span class="c"># Retrieve file from HDFS to local disk</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Retrieving $hdfs_file&quot;</span> &gt;&amp;2
</span><span class="line">/Users/sun1/repo/hadoop-3.1.2/bin/hdfs dfs -get <span class="nv">$hdfs_file</span> .
</span><span class="line"><span class="c"># Create local directory</span>
</span><span class="line"><span class="nv">target</span><span class="o">=</span><span class="sb">`</span>basename <span class="nv">$hdfs_file</span> .tar<span class="sb">`</span>
</span><span class="line">mkdir <span class="nv">$target</span>
</span><span class="line">
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Un-tarring $hdfs_file to $target&quot;</span> &gt;&amp;2
</span><span class="line">tar xf <span class="sb">`</span>basename <span class="nv">$hdfs_file</span><span class="sb">`</span> -C <span class="nv">$target</span>
</span><span class="line"><span class="c"># Unzip each station file and concat into one file</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Un-gzipping $target&quot;</span> &gt;&amp;2
</span><span class="line"><span class="k">for </span>file in <span class="nv">$target</span>/*
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">        </span>gunzip -c <span class="nv">$file</span> &gt;&gt; <span class="nv">$target</span>.all
</span><span class="line">        <span class="nb">echo</span> <span class="s2">&quot;reporter:status:Processed $file&quot;</span> &gt;&amp;2
</span><span class="line"><span class="k">done</span>
</span><span class="line"><span class="c"># Put gzipped version into HDFS</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Gzipping $target and putting in HDFS&quot;</span> &gt;&amp;2
</span><span class="line">gzip -c <span class="nv">$target</span>.all | /Users/sun1/repo/hadoop-3.1.2/bin/hdfs  dfs -put - /GSOD_ALL/<span class="nv">$target</span>.gz
</span><span class="line">rm <span class="sb">`</span>basename <span class="nv">$hdfs_file</span><span class="sb">`</span>
</span><span class="line">rm -r <span class="nv">$target</span>
</span><span class="line">rm <span class="nv">$target</span>.all
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后我们可以使用如下的方式来调用这个shell脚本了:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line">hadoop jar <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/share/hadoop/tools/lib/hadoop-streaming-3.1.2.jar <span class="se">\</span>
</span><span class="line">    -D mapreduce.job.reduces<span class="o">=</span>0 <span class="se">\</span>
</span><span class="line">    -D mapreduce.map.speculative<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
</span><span class="line">    -D mapreduce.task.timeout<span class="o">=</span>12000000 <span class="se">\</span>
</span><span class="line">    -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat <span class="se">\</span>
</span><span class="line">    -input /ncdc_files.txt <span class="se">\</span>
</span><span class="line">    -output /output/gsod <span class="se">\</span>
</span><span class="line">    -mapper load_ncdc_map.sh <span class="se">\</span>
</span><span class="line">    -file load_ncdc_map.sh
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>最后运行完了，我们可以check下目标文件是否生成</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -ls /GSOD_ALL
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>以及检查输出的结果</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -cat /output/gsod/part-00053
</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建Superset数据报表平台]]></title>
    <link href="http://isunix.github.io/blog/2019/05/23/da-jian-supersetshu-ju-bao-biao-ping-tai/"/>
    <updated>2019-05-23T17:04:08+08:00</updated>
    <id>http://isunix.github.io/blog/2019/05/23/da-jian-supersetshu-ju-bao-biao-ping-tai</id>
    <content type="html"><![CDATA[<p>主要参考链接<a href="https://superset.incubator.apache.org/installation.html">https://superset.incubator.apache.org/installation.html</a></p>

<ol>
  <li>如果想看superset的版本</li>
</ol>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">superset version -v
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[怎样无需手动输入密码连接PostgreSQL]]></title>
    <link href="http://isunix.github.io/blog/2019/05/23/zen-yang-wu-xu-shou-dong-shu-ru-mi-ma-lian-jie-postgresql/"/>
    <updated>2019-05-23T08:44:13+08:00</updated>
    <id>http://isunix.github.io/blog/2019/05/23/zen-yang-wu-xu-shou-dong-shu-ru-mi-ma-lian-jie-postgresql</id>
    <content type="html"><![CDATA[<p>我们要想不每次手动输入密码来连接PostgreSQL, 可以在home目录创建一个pgpass文件<code>touch ~/.pgpass</code>.
然后在里面输入如下的信息<code>$host:$port:$db:$user:$password</code>.
这里的每个变量实际过程中替换成真实的值.
然后我们就可以使用如下的方式来进行psql的连接了<code>psql -h $host -p $port -U $user -d $db</code>.
同理，这里的每个变量实际过程中替换成真实的值.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用rpm安装crontab命令备忘]]></title>
    <link href="http://isunix.github.io/blog/2019/05/22/shi-yong-rpman-zhuang-crontabming-ling-bei-wang/"/>
    <updated>2019-05-22T16:36:21+08:00</updated>
    <id>http://isunix.github.io/blog/2019/05/22/shi-yong-rpman-zhuang-crontabming-ling-bei-wang</id>
    <content type="html"><![CDATA[<p>我这边有台ec2, 但是在yum update的时候，总是报错说依赖冲突，后来处理这个问题的时候，过于激进，导致yum不可以用了, 最后把rpm也删了</p>

<p>参考这篇文章
<a href="https://blog.seosiwei.com/detail/27">https://blog.seosiwei.com/detail/27</a>
里的方法2，把rpm和yum都删了然后重装了, 软件下载链接是
<a href="http://mirrors.ustc.edu.cn/centos/6/os/x86_64/Packages/">http://mirrors.ustc.edu.cn/centos/6/os/x86_64/Packages/</a></p>

<p>安装好了之后，发现yum还是不能用，总是报错</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">liblzma.so.0: cannot open shared object file: No such file or directory</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>之类的信息</p>

<p>无可奈何，只好使用rpm了, 我这边需要使用crontab，于是从上面的软件库中下载了</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cronie-1.4.4-16.el6_8.2.x86_64.rpm``` 和 ```crontabs-1.10-33.el6.noarch.rpm</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后执行如下的命令来安装</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">rpm -Uvh --replacepkgs --nodeps --force cron*.rpm</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后报各种依赖找不到的错误, 比如</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">librpmio.so.3 not found</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>之类的</p>

<p>好在我们有别的ec2，我们可以去这个另外的ec2上找对应的依赖，然后copy到这个我们出问题的机器上</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">find / -name librpm.so.3 -type f</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后发现在/usr/lib64中，librpm.so.3是个软连接，指向/usr/lib64中的librpm.so.3.2.2, 我们把librpm.so.3.2.2copy到我们出问题的机器的/usr/lib64里，然后参照
<a href="http://isunix.github.io/blog/2019/05/22/linuxming-ling-lnde-shi-yong-bei-wang/">http://isunix.github.io/blog/2019/05/22/linuxming-ling-lnde-shi-yong-bei-wang/</a>
中的方式来做个软连接</p>

<p>仿照这个方式，如果还有问题，重复找依赖-copy-做软连接的过程</p>

<p>最后再执行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">rpm -Uvh --replacepkgs --nodeps --force cron*.rpm</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>crontab命令成功安装了.</p>
]]></content>
  </entry>
  
</feed>
