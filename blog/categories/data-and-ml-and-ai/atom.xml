<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[catogories：Data&ML&AI | Steven's Blog]]></title>
  <link href="http://isunix.github.io/blog/categories/data-and-ml-and-ai/atom.xml" rel="self"/>
  <link href="http://isunix.github.io/"/>
  <updated>2019-08-14T14:02:46+08:00</updated>
  <id>http://isunix.github.io/</id>
  <author>
    <name><![CDATA[Steven Sun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Gradient Boosting Algorithm]]></title>
    <link href="http://isunix.github.io/blog/2019/08/14/gradient-boosting-algorithm/"/>
    <updated>2019-08-14T13:51:36+08:00</updated>
    <id>http://isunix.github.io/blog/2019/08/14/gradient-boosting-algorithm</id>
    <content type="html"><![CDATA[<p>Gradient Boosting Algorithm 算法参考链接：</p>

<ul>
  <li>
    <p><a href="https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/">Which algorithm takes the crown: Light GBM vs XGBOOST?</a></p>
  </li>
  <li>
    <p><a href="https://www.analyticsvidhya.com/blog/2015/09/complete-guide-boosting-methods/">Learn Gradient Boosting Algorithm for better predictions (with codes in R)</a></p>
  </li>
  <li>
    <p><a href="https://www.analyticsvidhya.com/blog/2015/05/boosting-algorithms-simplified/">Getting smart with Machine Learning – AdaBoost and Gradient Boost</a></p>
  </li>
  <li>
    <p><a href="https://www.analyticsvidhya.com/blog/2015/11/quick-introduction-boosting-algorithms-machine-learning/">Quick Introduction to Boosting Algorithms in Machine Learning</a></p>
  </li>
  <li>
    <p><a href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/">Complete Machine Learning Guide to Parameter Tuning in Gradient Boosting (GBM) in Python</a></p>
  </li>
  <li>
    <p><a href="https://segmentfault.com/a/1190000014040317">XGboost数据比赛实战之调参篇</a></p>
  </li>
  <li>
    <p><a href="http://www.sohu.com/a/226265476_609569">通俗的将Xgboost的原理讲明白</a></p>
  </li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于P值]]></title>
    <link href="http://isunix.github.io/blog/2019/08/07/guan-yu-pzhi/"/>
    <updated>2019-08-07T13:45:59+08:00</updated>
    <id>http://isunix.github.io/blog/2019/08/07/guan-yu-pzhi</id>
    <content type="html"><![CDATA[<p>参考链接:</p>

<p><a href="https://towardsdatascience.com/p-values-explained-by-data-scientist-f40a746cfc8">p值是什么？数据科学家用最简单的方式告诉你</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于正态分布还有偏度与峰度]]></title>
    <link href="http://isunix.github.io/blog/2019/08/02/guan-yu-zheng-tai-fen-bu-huan-you-pian-du-yu-feng-du/"/>
    <updated>2019-08-02T08:29:35+08:00</updated>
    <id>http://isunix.github.io/blog/2019/08/02/guan-yu-zheng-tai-fen-bu-huan-you-pian-du-yu-feng-du</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Spark的MLlib进行机器学习]]></title>
    <link href="http://isunix.github.io/blog/2019/08/01/shi-yong-sparkde-mllibjin-xing-ji-qi-xue-xi/"/>
    <updated>2019-08-01T17:55:54+08:00</updated>
    <id>http://isunix.github.io/blog/2019/08/01/shi-yong-sparkde-mllibjin-xing-ji-qi-xue-xi</id>
    <content type="html"><![CDATA[<p>1.比如我们有个 case class</p>

<p><code>scala
case class CaseClassTest(user: String, name: String)
</code></p>

<p>我们通过使用<code>mapPartitions</code>来进行操作， 注意此处<code>mapPartitions</code>的用法:</p>

<p><code>scala
val mapResult = spark.read.textFile(input).map(_.split("\t")).mapPartitions {
      iter =&gt;
        iter.map {
          iterms =&gt; CaseClassTest(iterms(0), iterms(1))
        }
    }
</code></p>

<p>2.reduceByKey<code>  和 </code>case` 的用法</p>

<p><code>scala
val data = gowalla.map {
      check: CheckIn =&gt; (check.user, (1L, Set(check.time), Set(check.location)))
    }.rdd.reduceByKey{
      case (left, right) =&gt; (left._1 + right._1, left._2.union(right._2),left._3.union(right._3))
    }.map{
      case (_, (checkins, days:Set[String], locations:Set[String])) =&gt;
        Vectors.dense(checkins.toDouble, days.size.toDouble, locations.size.toDouble)
        //次数，天数，地点数
    }
</code></p>

<p><code>reduceByKey</code> 这里是求 <code>(1L, Set(check.time), Set(check.location))</code> 中的一个元素累加，第二个元素求并集，第三个元素也是求并集. <code>case</code> 的作用是让输入符合规范； 注意在 <code>map</code> 中，我们可以限定指示变量的类型， 比如这里的 <code>check: CheckIn =&gt;</code></p>

<h4 id="section">参考</h4>

<ol>
  <li>Spark机器学习进阶实战</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python中从ndarray或者DataFrame里获取数据和标签]]></title>
    <link href="http://isunix.github.io/blog/2019/07/23/pythonzhong-cong-ndarrayhuo-zhe-dataframeli-huo-qu-shu-ju-he-biao-qian/"/>
    <updated>2019-07-23T11:27:22+08:00</updated>
    <id>http://isunix.github.io/blog/2019/07/23/pythonzhong-cong-ndarrayhuo-zhe-dataframeli-huo-qu-shu-ju-he-biao-qian</id>
    <content type="html"><![CDATA[<p>如果我们有一个ndarray, 最后一列是label，前面几列是data, 我们可以通过如下的方式去获取数据(假如我们有9列):</p>

<p><code>
X = dataset[:,0:-1] or X = dataset[:,0:8]
Y = dataset[:,8]
</code></p>

<p>如果我们有个DataFrame, 我们可以通过如下的方式去获取:</p>

<p><code>
X, y = data.iloc[:,:-1], data.iloc[:,-1]
</code></p>

]]></content>
  </entry>
  
</feed>
