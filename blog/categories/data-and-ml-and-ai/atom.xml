<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[catogories：Data&ML&AI | Steven's Blog]]></title>
  <link href="http://isunix.github.io/blog/categories/data-and-ml-and-ai/atom.xml" rel="self"/>
  <link href="http://isunix.github.io/"/>
  <updated>2020-12-12T16:43:05+08:00</updated>
  <id>http://isunix.github.io/</id>
  <author>
    <name><![CDATA[Steven Sun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Matplotlib和Seaborn使用方法集锦]]></title>
    <link href="http://isunix.github.io/blog/2020/12/11/matplotlibhe-seabornshi-yong-fang-fa-ji-jin/"/>
    <updated>2020-12-11T11:41:28+08:00</updated>
    <id>http://isunix.github.io/blog/2020/12/11/matplotlibhe-seabornshi-yong-fang-fa-ji-jin</id>
    <content type="html"><![CDATA[<h4 id="section">1. 引入常用的包</h4>

<p><code>py
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns
</code></p>

<h4 id="pairplot">2. 选定若干列，画pairplot</h4>

<p>```py
sns.pairplot(college.iloc[:,1:11])</p>

<p>sns.pairplot(auto) # 选择全部列的数据
```</p>

<h4 id="boxplot">3. 选定两列，画出来boxplot</h4>

<p><code>py
sns.boxplot(x = college['Private'],y = college['Outstate'])
</code></p>

<h4 id="bar">4. 通过bar画直方图</h4>

<p>```py
fig = plt.figure()</p>

<p>plt.subplot(2,2,1) college[‘Enroll’].value_counts().plot.bar(title = ‘Enroll’)</p>

<p>plt.subplot(2,2,2) college[‘PhD’].value_counts().plot.bar(title = ‘PhD’)</p>

<p>plt.subplot(2,2,3) college[‘Terminal’].value_counts().plot.bar(title = ‘Terminal’)</p>

<h1 id="to-add-space-in-between-the-subplots">to add space in between the subplots</h1>
<p>fig.subplots_adjust(hspace=1)
```</p>

<h4 id="section-1">5. 画出散点图和曲线图，并且设置线的颜色</h4>

<p><code>py
plt.figure(figsize = (14,8)) 
plt.scatter(auto['horsepower'],auto['mpg']) 
plt.plot(auto['horsepower'],pred_1,color = 'orange') 
plt.plot(auto['horsepower'],pred_2,color = 'green') 
plt.plot(auto['horsepower'],pred_5,color = 'black') 
plt.show()
</code></p>

<h4 id="x">6. 绘制平行于x轴的水平参考线</h4>

<p><code>py
error_1 = auto['mpg'] - pred_1 
plt.figure(figsize = (12,6)) 
sns.scatterplot(x = auto['mpg'],y = error_1) 
plt.axhline(y = 0,linestyle = 'dashed',color = 'black',linewidth = 0.5)
</code></p>

<h4 id="snsregplot">7. 用sns.regplot来比较两个变量的关系是否符合线性回归</h4>

<p>```py
sns.regplot(data[‘LSTAT’],data[‘MEDV’])</p>

<h1 id="regplot">regplot中设置参数</h1>
<p>sns.regplot(advertising.TV, advertising.Sales, order=1, ci=None, scatter_kws={‘color’:’r’, ‘s’:9})
plt.xlim(-10,310)
plt.ylim(ymin=0);
```</p>

<h4 id="labeltitle">8. 设置label和title和</h4>

<p><code>py
plt.xlabel('Fitted Vales') 
plt.ylabel('Residuals') 
plt.title('Residual Plot')
</code></p>

<h4 id="sns">9. 使用sns画相关系数矩阵的热力图</h4>

<p><code>py
sns.heatmap(auto.iloc[:,:-1].corr())
</code></p>

<h4 id="labellegend">10. 设置线的label并且置成legend</h4>

<p>```py
plt.figure(figsize = (14,6)) 
sns.scatterplot(X,Y) 
plt.xlabel(‘X’) 
plt.ylabel(‘Y’) </p>

<p>plt.plot(data[‘X’],lin_model.predict(data[‘X’].to_frame()),color = ‘orange’,label = ‘Predicted Line’) 
plt.title(‘Relationship b/w X and Y’) 
plt.plot(tmp_x,tmp_y,color = ‘green’,label = ‘True Line’) 
plt.legend()
plt.show()
```</p>

<h4 id="section-2">11. 设置坐标范围, 设置相等的宽和高</h4>

<p>```py
fig, ax = plt.subplots()</p>

<p>sns.scatterplot(simple_coeff,multi_coeff)</p>

<p>lims = [
    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes
    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes
]</p>

<p>ax.plot(lims, lims, ‘k-‘, alpha=0.75, zorder=0,color = ‘orange’)
ax.set_aspect(‘equal’)
ax.set_xlim(lims)
ax.set_ylim(lims)
```</p>

<h4 id="hue">12. 设置hue</h4>

<p>```py
plt.figure(figsize = (12,8))</p>

<p>tmp = pd.DataFrame({‘Lag1’:X_train[‘Lag1’],’Lag2’:X_train[‘Lag2’],’Direction’:y_train})</p>

<p>sns.scatterplot(y = ‘Lag2’,x = ‘Lag1’,hue = ‘Direction’,data = tmp)
```</p>

<h4 id="section-3">13. 画等高线和三维图</h4>

<p>```py
fig = plt.figure(figsize=(15,6))
fig.suptitle(‘RSS - Regression coefficients’, fontsize=20)</p>

<p>ax1 = fig.add_subplot(121)
ax2 = fig.add_subplot(122, projection=’3d’)</p>

<h1 id="left-plot">Left plot</h1>
<p>CS = ax1.contour(xx, yy, Z, cmap=plt.cm.Set1, levels=[2.15, 2.2, 2.3, 2.5, 3])
ax1.scatter(regr.intercept<em>, regr.coef</em>[0], c=’r’, label=min_RSS)
ax1.clabel(CS, inline=True, fontsize=10, fmt=’%1.1f’)</p>

<h1 id="right-plot">Right plot</h1>
<p>ax2.plot_surface(xx, yy, Z, rstride=3, cstride=3, alpha=0.3)
ax2.contour(xx, yy, Z, zdir=’z’, offset=Z.min(), cmap=plt.cm.Set1,
            alpha=0.4, levels=[2.15, 2.2, 2.3, 2.5, 3])
ax2.scatter3D(regr.intercept<em>, regr.coef</em>[0], min_rss, c=’r’, label=min_RSS)
ax2.set_zlabel(‘RSS’)
ax2.set_zlim(Z.min(),Z.max())
ax2.set_ylim(0.02,0.07)</p>

<h1 id="settings-common-to-both-plots">settings common to both plots</h1>
<p>for ax in fig.axes:
    ax.set_xlabel(r’$\beta<em>0$’, fontsize=17)
    ax.set_ylabel(r’$\beta</em>1$’, fontsize=17)
    ax.set_yticks([0.03,0.04,0.05,0.06])
    ax.legend()
```</p>

<h4 id="d">14. 3D散点图</h4>

<p>```py
# Create plot
fig = plt.figure(figsize=(10,6))
fig.suptitle(‘Regression: Sales ~ Radio + TV Advertising’, fontsize=20)</p>

<p>ax = axes3d.Axes3D(fig)</p>

<p>ax.plot_surface(B1, B2, Z, rstride=10, cstride=5, alpha=0.4)
ax.scatter3D(advertising.Radio, advertising.TV, advertising.Sales, c=’r’)</p>

<p>ax.set_xlabel(‘Radio’)
ax.set_xlim(0,50)
ax.set_ylabel(‘TV’)
ax.set_ylim(ymin=0)
ax.set_zlabel(‘Sales’)
```</p>

<h4 id="suptitleclabel">15. suptitle、用clabel为等高线添加高程标签</h4>

<p>```py
fig = plt.figure(figsize=(12,5))
fig.suptitle(‘RSS - Regression coefficients’, fontsize=20)</p>

<p>ax1 = fig.add_subplot(121)
ax2 = fig.add_subplot(122)</p>

<p>min_RSS = r’$\beta<em>0$, $\beta</em>1$ for minimized RSS’</p>

<h1 id="left-plot-1">Left plot</h1>
<p>CS = ax1.contour(X1, Y1, Z1, cmap=plt.cm.Set1, levels=[21.25, 21.5, 21.8])
ax1.scatter(regr1.coef<em>[1], regr1.coef</em>[0], c=’r’, label=min_RSS)
ax1.clabel(CS, inline=True, fontsize=10, fmt=’%1.1f’)
ax1.set_ylabel(r’$\beta_{Age}$’, fontsize=17)</p>

<h1 id="right-plot-1">Right plot</h1>
<p>CS = ax2.contour(X2, Y2, Z2, cmap=plt.cm.Set1, levels=[21.5, 21.8])
ax2.scatter(regr2.coef<em>[1], regr2.coef</em>[0], c=’r’, label=min_RSS)
ax2.clabel(CS, inline=True, fontsize=10, fmt=’%1.1f’)
ax2.set_ylabel(r’$\beta_{Rating}$’, fontsize=17)
ax2.set_xticks([-0.1, 0, 0.1, 0.2])</p>

<p>for ax in fig.axes:
    ax.set_xlabel(r’$\beta_{Limit}$’, fontsize=17)
    ax.legend()
```</p>

<h4 id="section-4">16. 同时画两种不同的散点图</h4>

<p>```py
fig = plt.figure(figsize=(12,5))
gs = mpl.gridspec.GridSpec(1, 4)
ax1 = plt.subplot(gs[0,:-2])
ax2 = plt.subplot(gs[0,-2])
ax3 = plt.subplot(gs[0,-1])</p>

<h1 id="take-a-fraction-of-the-samples-where-target-value-default-is-no">Take a fraction of the samples where target value (default) is ‘no’</h1>
<p>df_no = df[df.default2 == 0].sample(frac=0.15)
# Take all samples  where target value is ‘yes’
df_yes = df[df.default2 == 1]
df_ = df_no.append(df_yes)</p>

<p>ax1.scatter(df<em>[df</em>.default == ‘Yes’].balance, df<em>[df</em>.default == ‘Yes’].income, s=40, c=’orange’, marker=’+’,
            linewidths=1)
ax1.scatter(df<em>[df</em>.default == ‘No’].balance, df<em>[df</em>.default == ‘No’].income, s=40, marker=’o’, linewidths=1,
             edgecolors=’lightblue’, facecolors=’white’, alpha=.6)</p>

<p>ax1.set_ylim(ymin=0)
ax1.set_ylabel(‘Income’)
ax1.set_xlim(xmin=-100)
ax1.set_xlabel(‘Balance’)</p>

<p>c_palette = {‘No’:’lightblue’, ‘Yes’:’orange’}
sns.boxplot(‘default’, ‘balance’, data=df, orient=’v’, ax=ax2, palette=c_palette)
sns.boxplot(‘default’, ‘income’, data=df, orient=’v’, ax=ax3, palette=c_palette)
gs.tight_layout(plt.gcf())
```</p>

<h3 id="section-5">参考资料</h3>

<ul>
  <li>github.com/JWarmenhoven/ISLR-python.git</li>
  <li>github.com.cnpmjs.org/hardikkamboj/An-Introduction-to-Statistical-Learning.git</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pandas使用tips集锦]]></title>
    <link href="http://isunix.github.io/blog/2020/12/11/pandasshi-yong-tipsji-jin/"/>
    <updated>2020-12-11T09:18:43+08:00</updated>
    <id>http://isunix.github.io/blog/2020/12/11/pandasshi-yong-tipsji-jin</id>
    <content type="html"><![CDATA[<h3 id="section">1. 替换字符</h3>

<p><code>py
auto['horsepower'] = auto['horsepower'].replace('?',np.nan)
</code></p>

<h3 id="section-1">2. 删除空值</h3>

<p><code>py
auto = auto.dropna()
</code></p>

<h3 id="section-2">3. 改变字段类型</h3>

<p><code>py
auto['horsepower'] = auto['horsepower'].astype('int')
</code></p>

<h3 id="section-3">4. 按照某一个/多个字段排序</h3>

<p>```py
auto = auto.sort_values(by = [‘horsepower’],ascending = True, axis = 0)</p>

<p>boston.sort_values(by= [‘CRIM’,’TAX’,’PTRATIO’],ascending=False).head().index
```</p>

<h3 id="pandas">5. pandas设置索引</h3>

<p><code>py
college = college.set_index(['Unnamed: 0'], append=True, verify_integrity=True) college.rename_axis([None, 'Name'], inplace=True)
</code> </p>

<h3 id="section-4">6. 对某一列进行判断并且置值</h3>

<p>```py
college[‘Elite’] = np.where(college[‘Top10perc’] &gt; 50,’Yes’,’No’)</p>

<h1 id="map">使用map的方式</h1>
<p>credit[‘Student2’] = credit.Student.map({‘No’:0, ‘Yes’:1})
```</p>

<h3 id="section-5">7. 对某一列的值进行计数</h3>

<p><code>py
college['Elite'].value_counts()
</code></p>

<h3 id="section-6">8. 对某一列的值进行筛选</h3>

<p><code>py
elite_colleges = college[college['Elite'] == 'Yes']
</code></p>

<h3 id="section-7">9. 对某一列的数值进行分桶操作</h3>

<p><code>py
college['Enroll'] = pd.cut(college['Enroll'], bins=3, labels = ['Low','Medium','High'])
</code></p>

<h3 id="dfunique">10. 查看df中的各个字段的unique的数目和字段类型信息等</h3>

<p><code>py
auto.nunique()
auto.info()
auto['horsepower'].unique() # 看某一列的unique数目
</code></p>

<h3 id="section-8">11. 筛选单列和多列</h3>

<p><code>py
info['range'] = info['max'] - info['min'] 
info = info[['mean','range','std']]
</code></p>

<h3 id="index">12. 根据index筛选和删除多列</h3>

<p><code>py
info = auto.drop(auto.index[10:85]).describe().T
</code></p>

<h3 id="load">13. load数据并且指定列名</h3>

<p>```py
boston = pd.DataFrame(load_boston().data,columns = load_boston().feature_names )</p>

<p>data = pd.DataFrame(boston.data,columns = boston[‘feature_names’])</p>

<p>```</p>

<h3 id="iloc">14. 通过iloc选取行和列</h3>

<p>```py
corr_matrix = boston.corr() 
corr_matrix.iloc[1:,0].sort_values() </p>

<h1 id="section-9">选取所有行，和从第二列开始的所有列</h1>
<p>data = data.iloc[:,1:]
```</p>

<h3 id="df">15. 按照行/列进行df的拼接</h3>

<p><code>py
# 按行拼接
features = pd.concat([constant,features],axis = 1)
</code></p>

<h3 id="load-1">16. load数据并且选定列</h3>

<p><code>py
credit = pd.read_csv('Data/Credit.csv', usecols=list(range(1,12)))
advertising = pd.read_csv('Data/Advertising.csv', usecols=[1,2,3,4])
</code></p>

<h3 id="section-10">17. 读取数据的时候，就设置空值的表示方法</h3>

<p><code>py
auto = pd.read_csv('Data/Auto.csv', na_values='?').dropna()
</code></p>

<h3 id="pandasdf">18. 构造pandas的df</h3>

<p><code>py
X = np.random.normal(size = 100) 
y = np.random.permutation(X) 
data = pd.DataFrame({'X':X,'y':y})
</code></p>

<h3 id="section-11">19. 读取文本文件的时候，设置某列为索引列</h3>

<p><code>py
data = pd.read_csv('../data/Smarket.csv',index_col=0)
</code></p>

<h3 id="section-12">20. 原地替换</h3>

<p><code>py
df_x.replace(to_replace={0:'No', 1:'Yes', 'True':'Yes', 'False':'No'}, inplace=True)
</code></p>

<h2 id="section-13">参考链接</h2>

<ul>
  <li>
    <p><a href="https://blog.csdn.net/jingyi130705008/article/details/78162758">pandas中关于set_index和reset_index的用法</a></p>
  </li>
  <li>
    <p><a href="https://stackoverflow.com/questions/39283339/what-is-the-meaning-of-axis-attribute-in-a-pandas-dataframe">What is the meaning of “axis” attribute in a Pandas DataFrame?</a></p>
  </li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[单纯形法介绍和Python代码实现]]></title>
    <link href="http://isunix.github.io/blog/2020/11/30/dan-chun-xing-fa-jie-shao-he-pythondai-ma-shi-xian/"/>
    <updated>2020-11-30T09:31:44+08:00</updated>
    <id>http://isunix.github.io/blog/2020/11/30/dan-chun-xing-fa-jie-shao-he-pythondai-ma-shi-xian</id>
    <content type="html"><![CDATA[<h1 id="section">参考链接:</h1>
<ul>
  <li><a href="https://zhuanlan.zhihu.com/p/31644892">简单理解线性规划的单纯形算法</a></li>
  <li><a href="https://jeremykun.com/2014/06/02/linear-programming-and-the-most-affordable-healthy-diet-part-1/">Linear Programming and Healthy Diets
</a></li>
  <li><a href="https://jeremykun.com/2014/12/01/linear-programming-and-the-simplex-algorithm/">Linear Programming and the Simplex Algorithm
</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[文本主题挖掘浅尝辄止]]></title>
    <link href="http://isunix.github.io/blog/2020/11/24/wen-ben-zhu-ti-wa-jue-qian-chang-zhe-zhi/"/>
    <updated>2020-11-24T17:32:37+08:00</updated>
    <id>http://isunix.github.io/blog/2020/11/24/wen-ben-zhu-ti-wa-jue-qian-chang-zhe-zhi</id>
    <content type="html"><![CDATA[<h2 id="section">关键词:</h2>

<p><code>向量</code>, <code>分布</code>, <code>期望</code>, <code>隐含狄利克雷分布</code>, <code>贝叶斯模型</code>, <code>先验分布</code>, <code>似然</code>, <code>后验分布</code>, <code>二项分布</code>, <code>Beta分布</code>, <code>Gamma函数</code>, <code>多项分布</code>, <code>Dirichlet 分布</code>, <code>文档</code>, <code>词</code>, <code>主题</code>, <code>超参数</code>, <code>Gibbs采样</code>, <code>变分推断EM</code>, <code>联合分布</code>, <code>条件分布</code>, <code>状态转移矩阵</code>, <code>马尔科夫链</code>, <code>平稳</code>, <code>二维正态分布</code>,  <code>变分推断</code>, <code>EM算法</code>, <code>KL散度</code>, <code>KL距离</code>, <code>交叉熵</code>, <code>变分分布</code>, <code>Jensen不等式</code>, <code>凸函数</code>, <code>正则</code>, <code>分词</code>, <code>bow(bag of word)</code>, <code>相似度度量</code></p>

<h2 id="section-1">代码:</h2>

<p>```python
import re
import sys
import jieba</p>

<p>user_dict_file = “my_dict_watch_77.csv”
jieba.load_userdict(user_dict_file)</p>

<p>stop_words_file = “hit_stopwords.txt”
stopwords = open(stop_words_file, ‘r’, encoding = ‘utf8’).readlines()
stopwords = [w.strip() for w in stopwords]</p>

<p>file_to_process = “watch_77.csv”</p>

<p>def word_cut(input_file):
    result_arr = []</p>

<pre><code>with open(file_to_process, 'r') as f:
for line in f.readlines():
    line = line.strip()
    if len(line) &lt; 3:
        continue

    out_str = ""
    re_chinese = re.compile(u"[\u4e00-\u9fa5]+")
    w = re.sub(r'[A-Za-z0-9]|\d+', '', str(line)) # removed chars, but what about "app"? 
    seg_list = jieba.lcut(w, cut_all=False)

    for word in seg_list:
        if word not in stopwords and word != '\t' and re_chinese.search(word, 0) and len(word.strip()) &gt;= 2:
            out_str += word
            out_str += " "

    result_arr.append(out_str.strip().split(" "))
return result_arr
</code></pre>

<p>seg_out_file = “out_file_20201124.txt”
result_arr = word_cut(file_to_process)</p>

<p>with open(seg_out_file, ‘w’,encoding = ‘utf-8’) as file:
        file.write(str(result_arr))</p>

<p>from jieba import analyse
tfidf = analyse.extract_tags</p>

<p>with open(seg_out_file, ‘r’, encoding=’utf-8’) as file:
    texts = file.readlines()</p>

<p>keywords = jieba.analyse.extract_tags(str(texts),
                                      topK=150,
                                      withWeight=True,
                                      allowPOS=(‘nr’, ‘ns’, ‘nt’, ‘nz’, ‘n’, ‘vn’, ‘v’))
for item in keywords:
    print(item)</p>

<p>from gensim import corpora, models, similarities
from gensim.models import LdaModel
from gensim.corpora import Dictionary
import pyLDAvis
import pyLDAvis.gensim</p>

<p>dictionary = corpora.Dictionary(result_arr)
corpus = [dictionary.doc2bow(text) for text in result_arr]</p>

<p>lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)
lda.print_topics(2)</p>

<p>vis_data = pyLDAvis.gensim.prepare(lda, corpus, dictionary)
pyLDAvis.display(vis_data)
```</p>

<h2 id="section-2">参考:</h2>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">LDA wiki</a></li>
  <li><a href="https://juejin.cn/post/6844904094771970056">文本挖掘之LDA主题模型</a></li>
  <li><a href="https://scikit-learn.org/dev/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py">LDA sk-learn</a></li>
  <li><a href="https://github.com/Nitro/scalda">LDA Scala</a></li>
  <li><a href="https://github.com/XiaoMi/MiNLP/tree/main/minlp-tokenizer">MiNLP-Tokenizer</a></li>
  <li><a href="https://www.cnblogs.com/pinard/p/6831308.html">文本主题模型之LDA(一) LDA基础： 刘建平</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/263065290">文本主题模型之LDA</a></li>
  <li><a href="https://github.com/isnowfy/snownlp">snownlp</a></li>
  <li><a href="https://www.cnblogs.com/Luv-GEM/p/10881838.html">文本主题抽取：用gensim训练LDA模型</a></li>
  <li><a href="https://github.com/fxsjy/jieba">jieba</a></li>
  <li><a href="https://github.com/lancopku/pkuseg-python">pkuseg-python</a></li>
  <li><a href="https://github.com/kimmy-sil/Python-beginning-practice">中文分词处理</a></li>
  <li><a href="https://blog.csdn.net/qq_16633405/article/details/80578804">Doc2Bow简介与实践Demo</a></li>
  <li><a href="https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/">Beginners Guide to Topic Modeling in Python</a></li>
  <li><a href="https://blog.csdn.net/selinda001/article/details/80446766">主题模型 LDA 入门（附 Python 代码）</a></li>
  <li><a href="https://github.com/goto456/stopwords">中文常用停用词表</a></li>
  <li><a href="https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24">Topic Modeling and Latent Dirichlet Allocation (LDA) in Python</a></li>
  <li><a href="https://blog.csdn.net/vs412237401/article/details/52238248">用docsim/doc2vec/LSH比较两个文档之间的相似度</a></li>
  <li><a href="https://github.com/amueller/word_cloud">wordcloud</a></li>
  <li><a href="https://github.com/bmabey/pyLDAvis">pyLDAvis</a></li>
  <li><a href="https://blog.csdn.net/v\_july\_v/article/details/41209515">通俗理解LDA主题模型
</a></li>
  <li><a href="https://www.eecis.udel.edu/\~shatkay/Course/papers/UIntrotoTopicModelsBlei2011-5.pdf">Introduction to Probabilistic Topic Models
</a></li>
  <li><a href="https://github.com/nkhuyu/python-LDA">python-LDA Git Code</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SparkSQL入门和进阶]]></title>
    <link href="http://isunix.github.io/blog/2020/11/20/sparksqlru-men-he-jin-jie/"/>
    <updated>2020-11-20T22:08:55+08:00</updated>
    <id>http://isunix.github.io/blog/2020/11/20/sparksqlru-men-he-jin-jie</id>
    <content type="html"><![CDATA[<h2 id="section">常用的函数：</h2>

<p><code>select</code>、<code>lit</code>、<code>as</code>、<code>groupBy</code>、<code>agg</code>、<code>sum</code>、<code>as</code>、<code>where</code>、<code>withColumn</code>、 <code>col</code>、 <code>when</code>、 <code>otherwise</code>、 <code>join</code>、<code>withColumnRenamed</code>、 <code>isin</code>、 <code>cast</code>、 <code>$</code>、 <code>union</code>、 <code>gt</code>、 <code>struct</code>、<code>sort</code>、<code>desc</code>、<code>show</code>、<code>orderBy</code>、<code>asc</code>、<code>repartition</code>、<code>sortWithinPartitions</code>、<code>filter</code>、<code>selectExpr</code>、<code>pivot</code>、<code>expr</code>、<code>row_number</code>、<code>over</code>、 <code>partitionBy</code></p>

<p>```scala
df
.select($”id”,lit(1).as(“cnt”)) 
.groupBy(“idd”) 
.agg(sum(“cnt”).as(“total”))
.where(“total &gt;=” + cnt2) 
.select(“uid”,”total”)</p>

<p>```</p>

<h2 id="udf">UDF：</h2>

<p><code>spark.udf.register
</code></p>

<h2 id="section-1">参考链接:</h2>
<ul>
  <li><a href="https://blog.csdn.net/weixin_40652340/article/details/79207455">SparkSQL DSL开发
</a></li>
  <li><a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Column.html">Column</a></li>
  <li><a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">Dataset</a></li>
  <li><a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions\$.html">functions</a></li>
  <li><a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/index.html\#DataFrame=org.apache.spark.sql.Dataset\[org.apache.spark.sql.Row\]">sql</a></li>
  <li><a href="https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html">Scalar User Defined Functions (UDFs)
</a></li>
  <li><a href="https://www.cnblogs.com/Diyo/p/11410895.html">SparkSQL DSL 随便写写</a></li>
  <li><a href="https://blog.csdn.net/weixin_42419342/article/details/108918139?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~sobaiduend\~default-2-108918139.nonecase&amp;utm_term=sparksql中dsl&amp;spm=1000.2123.3001.4430">SparkSQL案例——用SQL和DSL两种语法格式，求出用户连续登录天数
</a></li>
</ul>
]]></content>
  </entry>
  
</feed>
