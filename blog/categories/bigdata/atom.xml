<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[catogories：BigData | Steven's Blog]]></title>
  <link href="http://isunix.github.io/blog/categories/bigdata/atom.xml" rel="self"/>
  <link href="http://isunix.github.io/"/>
  <updated>2019-07-07T15:47:43+08:00</updated>
  <id>http://isunix.github.io/</id>
  <author>
    <name><![CDATA[Steven Sun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Zeppelin搭配Presto]]></title>
    <link href="http://isunix.github.io/blog/2019/06/10/zeppelinda-pei-presto/"/>
    <updated>2019-06-10T17:57:13+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/10/zeppelinda-pei-presto</id>
    <content type="html"><![CDATA[<p>参考文章</p>

<p><code>https://stackoverflow.com/questions/35858606/presto-interpreter-in-zeppelin-on-emr</code></p>

<ul>
  <li>在 master 机器上安装 jdbc</li>
</ul>

<p><code>sh
sudo /usr/lib/zeppelin/bin/install-interpreter.sh --name jdbc
</code></p>

<p><code>sh
sudo stop zeppelin
sudo start zeppelin
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EMR中创建HUE的superuser]]></title>
    <link href="http://isunix.github.io/blog/2019/06/10/emrzhong-chuang-jian-huede-superuser/"/>
    <updated>2019-06-10T17:48:43+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/10/emrzhong-chuang-jian-huede-superuser</id>
    <content type="html"><![CDATA[<p>想要在 EMR 中创建 HUE 的 superuser， 可以使用如下的方式</p>

<p><code>sh
cd /usr/lib/hue/
sudo build/env/bin/hue  createsuperuser
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Presto问题debug]]></title>
    <link href="http://isunix.github.io/blog/2019/06/04/prestowen-ti-debug/"/>
    <updated>2019-06-04T10:27:51+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/04/prestowen-ti-debug</id>
    <content type="html"><![CDATA[<p>我们在执行presto-cli命名的时候，可以使用如下的方式 <code>presto-cli --catalog hive --schema $schema --output-format CSV_HEADER --server $ip:$port --debug</code></p>

<p>这样就会打印出诊断信息出来.</p>

<p>我们使用如下的命令看下presto-server的状态 <code>initctl list | grep -i presto</code></p>

<p><code>sudo stop presto-server</code> 这样来关闭 presto-server； <code>sudo start presto-server</code> 这样来开启.</p>

<p>如果想要看查看presto的log，可以去 <code>/var/log/presto</code>, 对于debug非常有用.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PySpark中引入col函数的方式]]></title>
    <link href="http://isunix.github.io/blog/2019/06/04/pysparkzhong-yin-ru-colhan-shu-de-fang-shi/"/>
    <updated>2019-06-04T08:59:32+08:00</updated>
    <id>http://isunix.github.io/blog/2019/06/04/pysparkzhong-yin-ru-colhan-shu-de-fang-shi</id>
    <content type="html"><![CDATA[<p>在python代码中通过 <code>from pyspark.sql.functions import col</code> 来引入 <code>col</code> 这个函数的时候，总是报错，找不到这个函数. 后来参考
<a href="https://stackoverflow.com/questions/40163106/cannot-find-col-function-in-pyspark">https://stackoverflow.com/questions/40163106/cannot-find-col-function-in-pyspark</a> 这个文章, <code>pip install pyspark-stubs</code> 再去引用就好了.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop权威指南ncdc数据准备工作备忘]]></title>
    <link href="http://isunix.github.io/blog/2019/05/30/hadoopquan-wei-zhi-nan-ncdcshu-ju-zhun-bei-gong-zuo-bei-wang/"/>
    <updated>2019-05-30T09:23:39+08:00</updated>
    <id>http://isunix.github.io/blog/2019/05/30/hadoopquan-wei-zhi-nan-ncdcshu-ju-zhun-bei-gong-zuo-bei-wang</id>
    <content type="html"><![CDATA[<p>&lt;Hadoop: The Definitive Guide, Fourth Edition&gt; <a href="http://hadoopbook.com">http://hadoopbook.com</a> 是本好书, 书中的例子用到了ncdc的数据<a href="ftp://ftp.ncdc.noaa.gov/pub/data/gsod/">ftp://ftp.ncdc.noaa.gov/pub/data/gsod/</a>，这个也是非常赞的。我们知道统计学大师Fisher当年就是在气象工作站，研究气象数据很多年，后来在统计学上面做出了卓越的成就。气象数据纷繁复杂，通过实际的气象数据来阅读这本书，会教会读者在真实的情况下，如何面对数据，这个要比用一些dummy数据做演示，效果好太多.</p>

<p>官网github上面的数据很少<a href="https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all">https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all</a>. 我们自己从上面的ncdc的链接中去下载，我们下载tar文件. 具体也可以参考这篇文章<a href="https://blog.csdn.net/mrcharles/article/details/50442367">https://blog.csdn.net/mrcharles/article/details/50442367</a></p>

<p>```sh
#!/bin/bash</p>

<h1 id="cd-gsod1901tar-tar1930">这里cd到你想下载到的目录, 每个文件的格式如下所示gsod_1901.tar, 发现tar文件竟然只有从1930年才不是空文件</h1>
<p>cdir=”$(cd <code>dirname $0</code>; pwd)”</p>

<p>for i in $(seq 1930 1960)
do
    wget –execute robots=off —accept=tar -r -np -nH –cut-dirs=4 - R index.html* ftp://ftp.ncdc.noaa.gov/pub/data/gsod/$i/
done
```</p>

<p>下载好了之后，我们把这些1930/gsod_1930.tar 之类的文件，重新命令为1930/1930.tar, 然后把所有的文件都放到一个本地的目录，起名叫gsod， 现在gsod目录里都是1930/1930.tar这样的文件了.</p>

<p>接下来我们在hdfs上创建目录，</p>

<p><code>sh
hdfs dfs -mkdir /GSOD /GSOD_ALL
</code></p>

<p>然后将本地的gsod文件夹里的文件都上传到/GSOD/里面去</p>

<p><code>sh
hdfs dfs -put gsod/* /GSOD/
</code></p>

<p>这个过程在我的本机上，先是出现了namenode找不到的问题，然后又出现了namenode in safemode，创建不了的问题, 解决办法是</p>

<p><code>sh
stop-all.sh
hdfs namenode -format
start-all.sh
hadoop dfsadmin -safemode leave
</code></p>

<p>然后重新执行</p>

<p><code>sh
hdfs dfs -put gsod/* /GSOD/
</code></p>

<p>接下来我们要做的就是在hadoop上处理这些数据了. 首先创建generate_input_list.sh来生成MR的input文件:</p>

<p>```sh
#!/bin/bash</p>

<p>a=$1
rm -rf ncdc_files.txt
hdfs dfs -rm /ncdc_files.txt</p>

<p>while [ $a -le $2 ]
do
        filename=”/GSOD/${a}/${a}.tar”
        echo “$filename” » ncdc_files.txt
        a=<code>expr $a + 1</code>
done</p>

<p>hdfs dfs -put ncdc_files.txt /
```</p>

<p>ncdc_files.txt中的每一行就是<code>/GSOD/1950/1950.tar</code>这样的数据.</p>

<p>然后我们来产生文件:</p>

<p><code>sh
sh generate_input_list.sh 1901 1956
</code></p>

<p>接下来我们来创建load_ncdc_map.sh脚本，在MapReduce的Streaming上正常运行</p>

<p>```sh
#!/bin/bash</p>

<p>read offset hdfs_file
echo -e “$offset\t$hdfs_file”</p>

<h1 id="retrieve-file-from-hdfs-to-local-disk">Retrieve file from HDFS to local disk</h1>
<p>echo “reporter:status:Retrieving $hdfs_file” &gt;&amp;2
/Users/sun1/repo/hadoop-3.1.2/bin/hdfs dfs -get $hdfs_file .
# Create local directory
target=<code>basename $hdfs_file .tar</code>
mkdir $target</p>

<p>echo “reporter:status:Un-tarring $hdfs_file to $target” &gt;&amp;2
tar xf <code>basename $hdfs_file</code> -C $target
# Unzip each station file and concat into one file
echo “reporter:status:Un-gzipping $target” &gt;&amp;2
for file in $target/*
do
        gunzip -c $file » $target.all
        echo “reporter:status:Processed $file” &gt;&amp;2
done
# Put gzipped version into HDFS
echo “reporter:status:Gzipping $target and putting in HDFS” &gt;&amp;2
gzip -c $target.all | /Users/sun1/repo/hadoop-3.1.2/bin/hdfs  dfs -put - /GSOD_ALL/$target.gz
rm <code>basename $hdfs_file</code>
rm -r $target
rm $target.all
```</p>

<p>然后我们可以使用如下的方式来调用这个shell脚本了:</p>

<p>```sh
#!/bin/bash</p>

<p>hadoop jar ${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-streaming-3.1.2.jar \
    -D mapreduce.job.reduces=0 \
    -D mapreduce.map.speculative=false \
    -D mapreduce.task.timeout=12000000 \
    -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat \
    -input /ncdc_files.txt \
    -output /output/gsod \
    -mapper load_ncdc_map.sh \
    -file load_ncdc_map.sh
```</p>

<p>最后运行完了，我们可以check下目标文件是否生成</p>

<p><code>sh
hdfs dfs -ls /GSOD_ALL
</code></p>

<p>以及检查输出的结果</p>

<p><code>sh
hdfs dfs -cat /output/gsod/part-00053
</code></p>

]]></content>
  </entry>
  
</feed>
