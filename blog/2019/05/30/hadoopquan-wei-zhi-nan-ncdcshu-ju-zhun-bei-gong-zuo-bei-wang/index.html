
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Hadoop权威指南ncdc数据准备工作备忘 - Steven's Blog</title>
  <meta name="author" content="Steven Sun">

  
  <meta name="description" content="&lt;Hadoop: The Definitive Guide, Fourth Edition&gt; http://hadoopbook.com 是本好书, 书中的例子用到了ncdc的数据ftp://ftp.ncdc.noaa.gov/pub/data/gsod/，这个也是非常赞的。 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://isunix.github.io/blog/2019/05/30/hadoopquan-wei-zhi-nan-ncdcshu-ju-zhun-bei-gong-zuo-bei-wang">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Steven's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  

</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Steven's Blog</a></h1>
  
    <h2>A Dream Land of Peace!</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:isunix.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about" class="nav-link">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Hadoop权威指南ncdc数据准备工作备忘</h1>
    
    
      <p class="meta">
        








  


<time datetime="2019-05-30T09:23:39+08:00" pubdate data-updated="true">2019 年5 月30 日</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>&lt;Hadoop: The Definitive Guide, Fourth Edition&gt; <a href="http://hadoopbook.com">http://hadoopbook.com</a> 是本好书, 书中的例子用到了ncdc的数据<a href="ftp://ftp.ncdc.noaa.gov/pub/data/gsod/">ftp://ftp.ncdc.noaa.gov/pub/data/gsod/</a>，这个也是非常赞的。我们知道统计学大师Fisher当年就是在气象工作站，研究气象数据很多年，后来在统计学上面做出了卓越的成就。气象数据纷繁复杂，通过实际的气象数据来阅读这本书，会教会读者在真实的情况下，如何面对数据，这个要比用一些dummy数据做演示，效果好太多.</p>

<p>官网github上面的数据很少<a href="https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all">https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all</a>. 我们自己从上面的ncdc的链接中去下载，我们下载tar文件. 具体也可以参考这篇文章<a href="https://blog.csdn.net/mrcharles/article/details/50442367">https://blog.csdn.net/mrcharles/article/details/50442367</a></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="c">#这里cd到你想下载到的目录, 每个文件的格式如下所示gsod_1901.tar, 发现tar文件竟然只有从1930年才不是空文件</span>
</span><span class="line"><span class="nv">cdir</span><span class="o">=</span><span class="s2">&quot;$(cd `dirname $0`; pwd)&quot;</span>
</span><span class="line">
</span><span class="line"><span class="k">for </span>i in <span class="k">$(</span>seq 1930 1960<span class="k">)</span>
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">    </span>wget --execute <span class="nv">robots</span><span class="o">=</span>off —accept<span class="o">=</span>tar -r -np -nH --cut-dirs<span class="o">=</span>4 - R index.html* ftp://ftp.ncdc.noaa.gov/pub/data/gsod/<span class="nv">$i</span>/
</span><span class="line"><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>下载好了之后，我们把这些1930/gsod_1930.tar 之类的文件，重新命令为1930/1930.tar, 然后把所有的文件都放到一个本地的目录，起名叫gsod， 现在gsod目录里都是1930/1930.tar这样的文件了.</p>

<p>接下来我们在hdfs上创建目录，</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -mkdir /GSOD /GSOD_ALL
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后将本地的gsod文件夹里的文件都上传到/GSOD/里面去</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -put gsod/* /GSOD/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>这个过程在我的本机上，先是出现了namenode找不到的问题，然后又出现了namenode in safemode，创建不了的问题, 解决办法是</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">stop-all.sh
</span><span class="line">hdfs namenode -format
</span><span class="line">start-all.sh
</span><span class="line">hadoop dfsadmin -safemode leave
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后重新执行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -put gsod/* /GSOD/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>接下来我们要做的就是在hadoop上处理这些数据了. 首先创建generate_input_list.sh来生成MR的input文件:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="nv">a</span><span class="o">=</span><span class="nv">$1</span>
</span><span class="line">rm -rf ncdc_files.txt
</span><span class="line">hdfs dfs -rm /ncdc_files.txt
</span><span class="line">
</span><span class="line"><span class="k">while</span> <span class="o">[</span> <span class="nv">$a</span> -le <span class="nv">$2</span> <span class="o">]</span>
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">        </span><span class="nv">filename</span><span class="o">=</span><span class="s2">&quot;/GSOD/${a}/${a}.tar&quot;</span>
</span><span class="line">        <span class="nb">echo</span> <span class="s2">&quot;$filename&quot;</span> &gt;&gt; ncdc_files.txt
</span><span class="line">        <span class="nv">a</span><span class="o">=</span><span class="sb">`</span>expr <span class="nv">$a</span> + 1<span class="sb">`</span>
</span><span class="line"><span class="k">done</span>
</span><span class="line">
</span><span class="line">hdfs dfs -put ncdc_files.txt /
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>ncdc_files.txt中的每一行就是<code>/GSOD/1950/1950.tar</code>这样的数据.</p>

<p>然后我们来产生文件:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sh generate_input_list.sh 1901 1956
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>接下来我们来创建load_ncdc_map.sh脚本，在MapReduce的Streaming上正常运行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="nb">read </span>offset hdfs_file
</span><span class="line"><span class="nb">echo</span> -e <span class="s2">&quot;$offset\t$hdfs_file&quot;</span>
</span><span class="line">
</span><span class="line"><span class="c"># Retrieve file from HDFS to local disk</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Retrieving $hdfs_file&quot;</span> &gt;&amp;2
</span><span class="line">/Users/sun1/repo/hadoop-3.1.2/bin/hdfs dfs -get <span class="nv">$hdfs_file</span> .
</span><span class="line"><span class="c"># Create local directory</span>
</span><span class="line"><span class="nv">target</span><span class="o">=</span><span class="sb">`</span>basename <span class="nv">$hdfs_file</span> .tar<span class="sb">`</span>
</span><span class="line">mkdir <span class="nv">$target</span>
</span><span class="line">
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Un-tarring $hdfs_file to $target&quot;</span> &gt;&amp;2
</span><span class="line">tar xf <span class="sb">`</span>basename <span class="nv">$hdfs_file</span><span class="sb">`</span> -C <span class="nv">$target</span>
</span><span class="line"><span class="c"># Unzip each station file and concat into one file</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Un-gzipping $target&quot;</span> &gt;&amp;2
</span><span class="line"><span class="k">for </span>file in <span class="nv">$target</span>/*
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">        </span>gunzip -c <span class="nv">$file</span> &gt;&gt; <span class="nv">$target</span>.all
</span><span class="line">        <span class="nb">echo</span> <span class="s2">&quot;reporter:status:Processed $file&quot;</span> &gt;&amp;2
</span><span class="line"><span class="k">done</span>
</span><span class="line"><span class="c"># Put gzipped version into HDFS</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Gzipping $target and putting in HDFS&quot;</span> &gt;&amp;2
</span><span class="line">gzip -c <span class="nv">$target</span>.all | /Users/sun1/repo/hadoop-3.1.2/bin/hdfs  dfs -put - /GSOD_ALL/<span class="nv">$target</span>.gz
</span><span class="line">rm <span class="sb">`</span>basename <span class="nv">$hdfs_file</span><span class="sb">`</span>
</span><span class="line">rm -r <span class="nv">$target</span>
</span><span class="line">rm <span class="nv">$target</span>.all
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后我们可以使用如下的方式来调用这个shell脚本了:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line">hadoop jar <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/share/hadoop/tools/lib/hadoop-streaming-3.1.2.jar <span class="se">\</span>
</span><span class="line">    -D mapreduce.job.reduces<span class="o">=</span>0 <span class="se">\</span>
</span><span class="line">    -D mapreduce.map.speculative<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
</span><span class="line">    -D mapreduce.task.timeout<span class="o">=</span>12000000 <span class="se">\</span>
</span><span class="line">    -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat <span class="se">\</span>
</span><span class="line">    -input /ncdc_files.txt <span class="se">\</span>
</span><span class="line">    -output /output/gsod <span class="se">\</span>
</span><span class="line">    -mapper load_ncdc_map.sh <span class="se">\</span>
</span><span class="line">    -file load_ncdc_map.sh
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>最后运行完了，我们可以check下目标文件是否生成</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -ls /GSOD_ALL
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>以及检查输出的结果</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -cat /output/gsod/part-00053
</span></code></pre></td></tr></table></div></figure></notextile></div>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Steven Sun</span></span>

      








  


<time datetime="2019-05-30T09:23:39+08:00" pubdate data-updated="true">2019 年5 月30 日</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/bigdata/'>BigData</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2019/05/23/da-jian-supersetshu-ju-bao-biao-ping-tai/" title="Previous Post: 搭建Superset数据报表平台">&laquo; 搭建Superset数据报表平台</a>
      
      
        <a class="basic-alignment right" href="/blog/2019/05/31/shi-yong-dou-ban-yuan-an-zhuang-pythonbao/" title="Next Post: 使用豆瓣源安装python包">使用豆瓣源安装python包 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2019/07/24/vscode-remote-yuan-cheng-kai-fa-yu-diao-shi/">VScode Remote 远程开发与调试</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/23/pythonzhong-cong-ndarrayhuo-zhe-dataframeli-huo-qu-shu-ju-he-biao-qian/">Python中从ndarray或者DataFrame里获取数据和标签</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/20/dui-da-shu-ju-fen-xi-fen-xi-gong-zuo-de-%5B%3F%5D-xie-si-kao/">对(大)数据分析工作的一些思考</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/08/sparkwen-jian-cao-zuo-bei-wang/">Spark文件操作备忘</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/07/ji-qi-xue-xi-de-liu-cheng-tu/">机器学习的流程图</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/05/ryu-yan-de-%5B%3F%5D-xie-ji-lu/">R语言的一些记录</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/04/shu-ju-fen-xi-he-ji-qi-xue-xi-%5B%3F%5D-xie-zhai-chao/">数据分析和机器学习一些摘抄</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/04/zui-jin-de-gong-zuo-de-%5B%3F%5D-xie-gan-xiang/">最近的工作的一些感想</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/04/numpyde-%5B%3F%5D-xie-shu-ju-chu-li-bei-wang/">Numpy的一些数据处理备忘</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/02/yong-pythonlai-fa-song-markdownge-shi-de-you-jian/">用Python来发送markdown格式的邮件</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/algorithms/'>Algorithms (8)</a></li>
<li class='category'><a href='/blog/categories/bigdata/'>BigData (10)</a></li>
<li class='category'><a href='/blog/categories/blog/'>Blog (6)</a></li>
<li class='category'><a href='/blog/categories/c/'>C (4)</a></li>
<li class='category'><a href='/blog/categories/data-and-ml-and-ai/'>Data&ML&AI (6)</a></li>
<li class='category'><a href='/blog/categories/django-and-flask/'>Django&Flask (5)</a></li>
<li class='category'><a href='/blog/categories/editor/'>Editor (2)</a></li>
<li class='category'><a href='/blog/categories/fun/'>Fun (1)</a></li>
<li class='category'><a href='/blog/categories/javascript/'>Javascript (4)</a></li>
<li class='category'><a href='/blog/categories/linux-and-mac/'>Linux&Mac (13)</a></li>
<li class='category'><a href='/blog/categories/php/'>PHP (5)</a></li>
<li class='category'><a href='/blog/categories/perl/'>Perl (50)</a></li>
<li class='category'><a href='/blog/categories/python/'>Python (9)</a></li>
<li class='category'><a href='/blog/categories/ruby/'>Ruby (1)</a></li>
<li class='category'><a href='/blog/categories/scala/'>Scala (1)</a></li>
<li class='category'><a href='/blog/categories/shell/'>Shell (12)</a></li>

  </ul>
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2019 - Steven Sun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
